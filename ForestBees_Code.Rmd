---
title: "Forest Bees Code"
author: "Cora Davies"
date: "9/6/2022"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)

library(tidyverse)
library(ggplot2)
library(ggpubr)
library(cowplot)
library(grid)
library(gridExtra)
library(gtable)
library(emmeans)
library(dunn.test)
library(ncf)
library(VennDiagram)
library(hrbrthemes)
library(tm)
library(proustr)
library(vegan)
library(iNEXT)
library(bipartite)
library(ape) 
library(caper)
library(nlme) 
library(lavaan) 
library(lme4)
library(DiagrammeR)
library(semPlot)
library(piecewiseSEM)
library(corrplot)
library(RColorBrewer)
library(mvabund)
library(lattice)
library(ade4)
library(dbplyr)
library(devEMF)
library(ggrepel)

```

This document was written and tested under R version 4.1.2.  

### DATA ANALYSIS    

This R markdown document contains the analyses conducted for "Forest restoration treatments enhance plant-pollinator networks via floral- and temperature-mediated resource cascades."

```{r}
# Set seed to ensure reproducability for modelling
set.seed(27) 

# Import data
  #Forest structure
Basal_area <- read.csv("Basal_Area.csv")
Tree_density <- read.csv("Tree_Density.csv")
Sky <- read.csv("CanopyOpenness.csv")

  #Nesting habitat
Ground_Cover <- read.csv("Ground_Cover.csv")
CWD <- read.csv("CWD.csv")

  #Temperature data
T1_Temp <- read.csv("TempData\\T1_Temp.csv")
T2_Temp <- read.csv("TempData\\T2_Temp.csv")
T3_Temp <- read.csv("TempData\\T3_Temp.csv")
T4_Temp <- read.csv("TempData\\T4_Temp.csv")
T5_Temp <- read.csv("TempData\\T5_Temp.csv")
T6_Temp <- read.csv("TempData\\T6_Temp.csv")
T7_Temp <- read.csv("TempData\\T7_Temp.csv")
T8_Temp <- read.csv("TempData\\T8_Temp.csv")
T9_Temp <- read.csv("TempData\\T9_Temp.csv")
T10_Temp <- read.csv("TempData\\T10_Temp.csv")
T11_Temp <- read.csv("TempData\\T11_Temp.csv")
T12_Temp <- read.csv("TempData\\T12_Temp.csv")
T13_Temp <- read.csv("TempData\\T13_Temp.csv")
T14_Temp <- read.csv("TempData\\T14_Temp.csv")
T15_Temp <- read.csv("TempData\\T15_Temp.csv")
C16_Temp <- read.csv("TempData\\C16_Temp.csv")
C17_Temp <- read.csv("TempData\\C17_Temp.csv")
C18_Temp <- read.csv("TempData\\C18_Temp.csv")
C19_Temp <- read.csv("TempData\\C19_Temp.csv")
C20_Temp <- read.csv("TempData\\C20_Temp.csv")
C21_Temp <- read.csv("TempData\\C21_Temp.csv")
C22_Temp <- read.csv("TempData\\C22_Temp.csv")
C23_Temp <- read.csv("TempData\\C23_Temp.csv")
C24_Temp <- read.csv("TempData\\C24_Temp.csv")
C25_Temp <- read.csv("TempData\\C25_Temp.csv")
C26_Temp <- read.csv("TempData\\C26_Temp.csv")
C27_Temp <- read.csv("TempData\\C27_Temp.csv")
C28_Temp <- read.csv("TempData\\C28_Temp.csv")
C29_Temp <- read.csv("TempData\\C29_Temp.csv")
C30_Temp <- read.csv("TempData\\C30_Temp.csv")

  #Foraging habitat
Floral_Quadrats <- read.csv("Floral_Quadrats.csv", header=TRUE) 

  #Bee species analyses
BeeID <- read.csv("BeeIdentification.csv", header=TRUE) 
SiteInfo <- read.csv("SiteInformation.csv", header=TRUE) 
traits <- read.csv("GenusTraits.csv", header=TRUE)

SEMvars <- read.csv("SEMvars.csv")

```

## Forest Structure
This section of the R Markdown document is for the analyses examining the effects of forest thinning on forest structure including:  
    -	Mean basal area  
    -	Mean tree density
    - Mean number of snags
    -	Average quadratic mean diameter  
    -	Canopy cover

# Mean basal area

Calculate the average basal area at each site (n=10/site) and convert data from ft^2 / acre to m^2 / hectare. _(1 square foot / acre = 0.229568411 square meters / hectare)_  

```{r}
#Calculate averages and save as new data frame
BAmeans <- group_by(Basal_area, Treatment, Site) %>% summarize(ba = mean(BA.live))

#Convert data to correct units
BAmeans <- BAmeans %>% add_column(BA_converted = (BAmeans$ba*0.229568411))

```

Analyze data using 2-sample t-test.

```{r}
#test equal variance
var.test(BA_converted ~ Treatment, data=BAmeans)
#test normality
shapiro.test(BAmeans$BA_converted)
hist(BAmeans$BA_converted)
#var not equal use Welch 
t.test(BA_converted ~ Treatment, data=BAmeans,
       conf.level=0.95)
#Calculate SE
BAsd <- BAmeans %>% group_by(Treatment) %>% summarize(sd = sd(BA_converted))
BAsd$sd/sqrt(15) #1=control; 2=thinned

```

Visualization: Create a box plot of the data. 

```{r}
#Plot data
BAplot <- ggplot(BAmeans, aes(x = Treatment, y = BA_converted, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab(expression(Basal~area~(m^2/ha)))+
  labs(x= "Treatment Type") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=42)

```

# Mean tree density

Calculate the number of trees per hectare based on the number of trees with in the 0.1ha plots. 

```{r}
#Calculate number of trees per hectare
Tree_density <- Tree_density %>% add_column(Trees_ha = (Tree_density$Total_Trees*10))

```

Analyze data using 2-sample t-test.

```{r}
#test equal variance
var.test(Trees_ha ~ Treatment, data=Tree_density)
#test normality
shapiro.test(Tree_density$Trees_ha)
hist(Tree_density$Trees_ha)
#var not equal use Welch 
t.test(Trees_ha ~ Treatment, data=Tree_density,
       conf.level=0.95)

#Calculate SE
Treesd <- Tree_density %>% group_by(Treatment) %>% summarize(sd = sd(Trees_ha))
Treesd$sd/sqrt(15) #1=control; 2=thinned

```

Visualization: create a box plot of the data. 

```{r}
#Plot data
Treedensityplot <- ggplot(Tree_density, aes(x = Treatment, y = Trees_ha, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab(expression(Tree~density~(trees/ha)))+
  labs(x= "Treatment Type") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=750)

```

# Average quadratic mean diameter

{\displaystyle {\sqrt {\frac {BA}{k*n}}}}

where BA is stand basal area, n is the number of trees, and k is a constant based on measurement units (for BA in m2 and DBH in cm, k=0.0000785).

```{r}
#Calculate the QMD using the tree density and basal area
  #add BA to tree density data
  Tree_density <- Tree_density %>% add_column(BA = (BAmeans$BA_converted))

  #calculate average QMD
  QMD <- sqrt((abs(Tree_density$BA))/(Tree_density$Trees_ha*0.0000785))

  #add QMD in new column
  Tree_density <-Tree_density %>% add_column(QMD =QMD)
```

Analyze data using 2-sample t-test.

```{r}
#test equal variance
var.test(QMD ~ Treatment, data=Tree_density)
#test normality
shapiro.test(Tree_density$QMD)
hist(Tree_density$QMD)

#variance equal
t.test(QMD ~ Treatment, data=Tree_density, var.equal = TRUE, conf.level=0.95)
#Calculate SE
QMDsd <- Tree_density %>% group_by(Treatment) %>% summarize(sd = sd(QMD))
QMDsd$sd/sqrt(15) #1=control; 2=thinned

```

Visualize: create a box plot of the data. 

```{r}
#Plot data
QMDplot <- ggplot(Tree_density, aes(x = Treatment, y = QMD, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("QMD (cm)")+
  labs(x= "Treatment Type") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=42, hide.ns=TRUE) +
  coord_cartesian(ylim = quantile(Tree_density$QMD, c(0, .97)))

```

# Canopy cover

Calculate mean canopy openness per sites (Using data from GLA). 

```{r}
#Calculate mean canopy openness per sites
meanSky <-  Sky %>% group_by(Treatment, Site) %>% summarize(Sky = mean(Sky))

```

Compare the data of thinned sites to non-thinned.

```{r}
#test equal variance
var.test(Sky ~ Treatment, data=meanSky)
#test normality
shapiro.test(meanSky$Sky)
hist(meanSky$Sky)
#variance not equal equal
t.test(Sky ~ Treatment, data=meanSky, var.equal = TRUE, conf.level=0.95)

#Calculate SE
Skysd <- meanSky %>% group_by(Treatment) %>% summarize(sd = sd(Sky))
Skysd$sd/sqrt(15) #1=control; 2=thinned

```

#Comparing average number of snags

Difference in snags: 

```{r}
#Calculate averages and save as new data frame
snags <- group_by(Basal_area, Treatment, Site) %>% summarize(meansnags = mean(Trees-Live))

#2-sample t-test
#test equal variance
var.test(meansnags ~ Treatment, data=snags)
#test normality
shapiro.test(snags$meansnags)
hist(snags$meansnags)
#var not equal use Welch 
t.test(meansnags ~ Treatment, data=snags,
       conf.level=0.95)

```

Visualize: create a box plot of the data and graphic of all forest structure variables

```{r}
#Plot sky data
Skyplot <- ggplot(meanSky, aes(x = Treatment, y = Sky, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Canopy openness (%)")+
  labs(x= "Treatment Type") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=100)

#Graphic for all forest structure variables
plot_grid(BAplot + theme(legend.position="none"), Treedensityplot + theme(legend.position="none"), Skyplot, align = "h", ncol = 3, rel_widths= c(1, 1, 1.5), labels="AUTO")

```

## Nesting habitat
This section of the R Markdown document is for the analyses examining the effects of forest thinning on nesting habitat including:  
    - Snags (see above)
    -	Bare ground cover
    - Fuel loads (woody debris)
    
# Ground Cover

Edit the data to count the abundance of each type.

```{r}
GC <- Ground_Cover %>% group_by(Site, Treatment, Cover_type) %>% summarize(frequency = n())

GC <- GC %>%
  spread(key = Cover_type, value = frequency)

#change NA cells to 0
GC <- GC %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))

#Save data
write.csv(GC, "GroundCover.csv")

```

We can run a t-test on any of the cover types to directly compare them...

```{r}
#check variance
var.test(Bare ~ Treatment, data=GC)
#Run Students 2-sample t-test
t.test(Bare ~ Treatment, data=GC,
       var.equal=TRUE,
       conf.level=0.95)
#Calculate SE
Baresd <- GC %>% group_by(Treatment) %>% summarize(sd = sd(Bare))
Baresd$sd/sqrt(15) #1=control; 2=thinned

```

Visualize: create a box plot of the data. 

```{r}
treatmentlabs <- (c("Control","Thinned"))

#Plot data
Bareplot <- ggplot(GC, aes(x = Treatment, y = Bare, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment)) + 
  ylab("Bare ground (% cover)")+
  labs(x= "Treatment Type") +
  scale_fill_grey(start = .5, end = .9, name="Treatment",
                         breaks=c("C", "T"),
                         labels=c("Control", "Thinned"))+ 
  scale_x_discrete(labels= treatmentlabs)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=.38)

```

# Fuel Loads

To analyze fuel loads the equation from Van Wagner (1968) was used. The next step is to calculate the volume for each site. 

```{r}
#reorder to match other data
CWD <- CWD %>% relocate(Site)

#Convert diameter from inches to cm
CWD <- CWD %>% mutate(Diameter = Diameter*2.54)

#create new column (d^2/800)- 800 is 8 times length (=100)
CWD <- CWD %>%
  mutate(Diameter2= ((Diameter^2)/800))

#add row for T9 since volume was zero
CWD <- CWD %>% add_row(Treatment = "Thinned", Site = "T9", Transect=1, Log_Number=1, Diameter=0, Decay="NA", Diameter2=0)

#create new data with summary of each site 
CWD_V <- CWD %>% group_by(Site, Treatment) %>% summarize(Volume = (pi^2 *(sum(Diameter2))))

#save data
write.csv(CWD_V, "CWD_V.csv")

```

Run t-test to compare between sites: 

```{r}
#check variance
var.test(Volume ~ Treatment, data=CWD_V)
#Run Students 2-sample t-test
t.test(Volume ~ Treatment, data=CWD_V,
       var.equal=TRUE,
       conf.level=0.95)
#Calculate SE
CWDsd <- CWD_V %>% group_by(Treatment) %>% summarize(sd = sd(Volume))
CWDsd$sd/sqrt(15) #1=control; 2=thinned

```

Visualize: create a box plot of the data. 

```{r}

treatmentlabs <- (c("Control","Thinned"))

#Plot data
CWDplot <- ggplot(CWD_V, aes(x = Treatment, y = Volume, fill = Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment)) + 
  ylab(expression(Volume~(m^3/ha)))+
  labs(x= "Treatment Type") +
  scale_fill_grey(start = .5, end = .9, name="Treatment",
                         breaks=c("C", "T"),
                         labels=c("Control", "Thinned"))+ 
  scale_x_discrete(labels= treatmentlabs)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

```

## Temperature
This section is to analyze temperature between thinned and non-thinned sites.

Combine all temperature data and summarize (mean, max, min).

```{r}
#calculate mean site temp
TempSummary <- data.frame(Site =c("T1","T2","T3","T4","T5","T6","T7","T8","T9","T10","T11","T12","T13","T14","T15","C16","C17","C18","C19","C20","C21","C22","C23","C24","C25","C26","C27","C28","C29","C30"),
                            Treatment=c("Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned", "Thinned","Thinned", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control", "Control"),
                          MeanTemp = c(mean(T1_Temp$Temp),mean(T2_Temp$Temp),mean(T3_Temp$Temp),mean(T4_Temp$Temp),mean(T5_Temp$Temp),mean(T6_Temp$Temp),mean(T7_Temp$Temp),mean(T8_Temp$Temp),mean(T9_Temp$Temp),mean(T10_Temp$Temp),mean(T11_Temp$Temp),mean(T12_Temp$Temp),mean(T13_Temp$Temp),mean(T14_Temp$Temp),mean(T15_Temp$Temp),mean(C16_Temp$Temp),mean(C17_Temp$Temp),mean(C18_Temp$Temp),mean(C19_Temp$Temp),mean(C20_Temp$Temp),mean(C21_Temp$Temp),mean(C22_Temp$Temp),mean(C23_Temp$Temp),mean(C24_Temp$Temp),mean(C25_Temp$Temp),mean(C26_Temp$Temp),mean(C27_Temp$Temp),mean(C28_Temp$Temp),mean(C29_Temp$Temp),mean(C30_Temp$Temp)),
                           MaxTemp = c(max(T1_Temp$Temp),max(T2_Temp$Temp),max(T3_Temp$Temp),max(T4_Temp$Temp),max(T5_Temp$Temp),max(T6_Temp$Temp),max(T7_Temp$Temp),max(T8_Temp$Temp),max(T9_Temp$Temp),max(T10_Temp$Temp),max(T11_Temp$Temp),max(T12_Temp$Temp),max(T13_Temp$Temp),max(T14_Temp$Temp),max(T15_Temp$Temp),max(C16_Temp$Temp),max(C17_Temp$Temp),max(C18_Temp$Temp),max(C19_Temp$Temp),max(C20_Temp$Temp),max(C21_Temp$Temp),max(C22_Temp$Temp),max(C23_Temp$Temp),max(C24_Temp$Temp),max(C25_Temp$Temp),max(C26_Temp$Temp),max(C27_Temp$Temp),max(C28_Temp$Temp),max(C29_Temp$Temp),max(C30_Temp$Temp)),
                            MinTemp = c(min(T1_Temp$Temp),min(T2_Temp$Temp),min(T3_Temp$Temp),min(T4_Temp$Temp),min(T5_Temp$Temp),min(T6_Temp$Temp),min(T7_Temp$Temp),min(T8_Temp$Temp),min(T9_Temp$Temp),min(T10_Temp$Temp),min(T11_Temp$Temp),min(T12_Temp$Temp),min(T13_Temp$Temp),min(T14_Temp$Temp),min(T15_Temp$Temp),min(C16_Temp$Temp),min(C17_Temp$Temp),min(C18_Temp$Temp),min(C19_Temp$Temp),min(C20_Temp$Temp),min(C21_Temp$Temp),min(C22_Temp$Temp),min(C23_Temp$Temp),min(C24_Temp$Temp),min(C25_Temp$Temp),min(C26_Temp$Temp),min(C27_Temp$Temp),min(C28_Temp$Temp),min(C29_Temp$Temp),min(C30_Temp$Temp))
                 )
#save data
write.csv(TempSummary, "TempSummary.csv")

#Run Students 2-sample t-test
  #Maximum temperature
t.test(MaxTemp ~ Treatment, data=TempSummary,
       var.equal=TRUE,
       conf.level=0.95)
  #Calculate SE
maxsd<- TempSummary %>% group_by(Treatment) %>% summarize(sd = sd(MaxTemp))
maxsd$sd/sqrt(15) #1=control; 2=thinned

  #Mean temperature
t.test(MeanTemp ~ Treatment, data=TempSummary,
       var.equal=TRUE,
       conf.level=0.95)
  #Calculate SE
meansd<- TempSummary %>% group_by(Treatment) %>% summarize(sd = sd(MeanTemp))
meansd$sd/sqrt(15) #1=control; 2=thinned

  #Minimum temperature
t.test(MinTemp ~ Treatment, data=TempSummary,
       var.equal=TRUE,
       conf.level=0.95)
  #Calculate SE
minsd<- TempSummary %>% group_by(Treatment) %>% summarize(sd = sd(MinTemp))
minsd$sd/sqrt(15) #1=control; 2=thinned

```

Visualize: create box plot.

```{r}
#Create figure
MeanTemp<- ggplot(TempSummary, aes(x=Treatment, y=MeanTemp, fill=Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Mean Temperature (°C)")+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=20)

MaxTemp<- ggplot(TempSummary, aes(x=Treatment, y=MaxTemp, fill=Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Maximum Temperature (°C)")+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=40)

MinTemp<- ggplot(TempSummary, aes(x=Treatment, y=MinTemp, fill=Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Minimum Temperature (°C)")+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

S2 <- ggarrange(MeanTemp, MaxTemp, MinTemp,
                    labels = c("A", "B", "C"),
                    ncol = 3, nrow = 1, common.legend=TRUE,legend="top")

```

## Foraging Habitat
The next section of this R Markdown document is for the analyses examining the effects of forest thinning on bee foraging resources. 

# Mean foral abundance
Mean floral abundance calculated using the number of flowers in each m^2 quadrat. Calculated the average number of flowers/m^2 in each site at each sampling time (month)

```{r}
#create new data frame with the average floral abundance at each site by month 

Floralab<- group_by(Floral_Quadrats, Treatment, Site, Month) %>% summarize(floralab = mean(Count))

Floralabpooled<-group_by(Floral_Quadrats, Site, Treatment) %>% summarize(floralab = sum(Count))

```

Create ANOVA model. Assumptions: assumptions of homoscedasticity (Levene's test) and normality (histograms). Variances are not equal by Levene's test and data is not normally distributed. Residuals v fitted also shows not equal variances. Normal Q-Q is heavily skewed. Shapiro-Wilk test residuals are not normally distributed.

```{r}
#Create the linear model 
lmflowerab <- lm(floralab ~ Treatment * Month, data=Floralab) 

#check normality 
par(mfrow=c(2,2))
plot(lmflowerab)

#run anova
anova(lmflowerab)
emout <- emmeans(lmflowerab, ~ Treatment*Month)
pairs(emout)

```

Plot data.

```{r}
#order by month
Floralab$Month <- factor(Floralab$Month,levels = c("June", "July", "August"))

#create box plots 
Floralabplot<- ggplot(Floralab, aes(x=Month, y=floralab, fill=Treatment)) + 
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab(expression(Floral~density~(count/m^2)))+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=10)+ coord_cartesian(ylim = quantile(Floralab$floralab, c(0, 0.99)))

FloralabSum <- Floralab %>%
  group_by(Month, Treatment) %>%
  summarise(n = n(),
            mean = mean(floralab))

#pooled across months
FloralabSumStats <- Floralab %>%
  group_by(Site,Treatment) %>%
  summarise(n = n(),
            mean = mean(floralab))

Floralabpooledplot<- ggplot(FloralabSumStats, aes(x=Treatment, y=mean, fill=Treatment)) + 
 geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab(expression(Floral~density~(count/m^2)))+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=.38)

#test equal variance
var.test(mean ~ Treatment, data=FloralabSumStats)
#variance not equal equal
t.test(mean ~ Treatment, data=FloralabSumStats, var.equal = TRUE, conf.level=0.95)
#Calculate SE
floralsd<- FloralabSumStats %>% group_by(Treatment) %>% summarize(sd = sd(mean))
floralsd$sd/sqrt(15) #1=control; 2=thinned

```

# Number of floral species

First calculate the floral species richness.  

```{r, warning=FALSE}
#create new data frame with the floral species richness at each site by month 

#Remove all rows with "None" listed as species
Floralrich <- Floral_Quadrats %>% 
  filter(!grepl('None', Species))

#Calculate floral richness
Floralrich <- Floralrich %>% group_by(Treatment,Site,Month) %>% 
  summarize(floralrich = length(unique(Species))) #counts unique values of species names
Floralrichpooled <- Floral_Quadrats %>% filter(!grepl('None', Species))%>% group_by(Site, Treatment) %>% 
  summarize(floralrich = length(unique(Species))) #counts unique values of species names
#add missing row
c17<-data.frame("C17","Control",0)
  #Naming the Data Frame
names(c17) <- c("Site", "Treatment", "floralrich")  
  #Using rbind() function to insert above observation  
Floralrichpooled <- rbind(Floralrichpooled, c17)  
#save as csv
write.csv(Floralrichpooled, "Floralrichpooled.csv")

#add missing rows to df
  #create missing rows
df4<- data.frame (c("Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control","Control"),
                  c("C16","C16","C17","C17","C17","C18","C18","C19","C20","C22","C23","C24","C25","C26","C26","C29","C30","C30"),
                  c("July","August","June","July","August","July","August","August","August","August","August","August","August","July","August","August","July","August"),
                  c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0))
  #Naming the Data Frame
names(df4) <- c("Treatment", "Site", "Month", "floralrich")  
  #Using rbind() function to insert above observation  
Floralrich <- rbind(Floralrich, df4)  

```

Next, create linear model and run ANOVA. Assumptions: assumptions of homoscedasticity (Levene's test) and normality (histograms). Variances are not equal by Levene's test and data is not normally distributed. Residuals v fitted also shows not equal variances. Normal Q-Q is heavily skewed. Shapiro-Wilk test residuals are not normally distributed.

```{r}
#create linear model
lmfloralrich <- lm(floralrich ~ Treatment * Month, data=Floralrich) 

#visually inspect to evaluate assumptions
par(mfrow=c(2,2))
plot(lmfloralrich)

#run anova
anova(lmfloralrich)
emout <- emmeans(lmfloralrich, ~ Treatment*Month)
pairs(emout)

#non-parametric test Kruskal-Wallis
kruskal.test(formula=floralrich~Treatment,data=Floralrich)
dunn.test(x=Floralrich$floralrich,g=Floralrich$Treatment)
dunn.test(x=Floralrich$floralrich,g=Floralrich$Month)

```

Plot data.

```{r}
#order by month
Floralrich$Month <- factor(Floralrich$Month,levels = c("June", "July", "August"))

#create box plots 
Floralrichplot<- ggplot(Floralrich, aes(x=Month, y=floralrich, fill=Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Floral species richness \n (# species)")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=8)+ coord_cartesian(ylim = quantile(Floralrich$floralrich, c(0.1, 0.99))) 

Floralrich1 <- Floralrich %>%
  group_by(Month,Treatment) %>%
  summarise(n = n(),
            mean = mean(floralrich))

#pooled across month
FloralrichSumStats <- Floralrich %>%
  group_by(Site,Treatment) %>%
  summarise(n = n(),
            mean = mean(floralrich))

Floralrichpooledplot<- ggplot(FloralrichSumStats, aes(x=Treatment, y=mean, fill=Treatment)) +
  geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab("Floral species richness \n (# species)")+
  xlab("Treatment Type")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+ stat_compare_means(method="t.test",label =  "p.signif", label.x = 1.5, label.y=.38)

#test equal variance
var.test(mean ~ Treatment, data=FloralrichSumStats)
#variance not equal equal
t.test(mean ~ Treatment, data=FloralrichSumStats, var.equal = TRUE, conf.level=0.95)
#Calculate SE
floralrichsd<- FloralrichSumStats %>% group_by(Treatment) %>% summarize(sd = sd(mean))
floralrichsd$sd/sqrt(15) #1=control; 2=thinned

```
Save all data created in new CSV file for future analyses.

```{r}
##FOREST STRUCTURE
#create new dataframe with all forest structure variables
ForestStructure<- Tree_density %>% add_column(Sky = meanSky$Sky, .after = "QMD")
#save data
write.csv(ForestStructure, "ForestStructure.csv")

##FORAGAING HABITAT

#create list of data frames to combine
data_list2 <- list(Floralab, Floralrich)     
#merge data
ForagaingHabitat<-data_list2 %>% reduce(inner_join, by = c("Site","Month","Treatment"))  
#save data
write.csv(ForagaingHabitat, "ForagingHabitat.csv")

#Create data list for pooled comment 
data_list3 <- list(Floralabpooled, Floralrichpooled)     
#merge data
ForagaingHabitatpooled<-data_list3 %>% reduce(inner_join, by = c("Site", "Treatment"))  
#save data
write.csv(ForagaingHabitatpooled, "ForagingHabitatpooled.csv")

```

Create figure with all items. 

```{r}
Fig3 <- ggarrange(BAplot, Treedensityplot, QMDplot, Skyplot, Floralabpooledplot, Floralrichpooledplot, Bareplot, CWDplot,
                    labels = "AUTO",
                    ncol = 4, nrow = 2, common.legend=TRUE,legend="top") 

S3 <- ggarrange(Floralabplot, Floralrichplot,
                    labels = c("A", "B"),
                    ncol = 1, nrow = 2, common.legend=TRUE,legend="top")

```

## Bee species analyses

    1) Two-factor ANOVA (Month and Treatment)
          A) Bee abundance
          B) Bee species richness
          C) Shannon-weiner diversity index (H')
    2) Sample curves (iNEXT package)
          A) Bee species diversity 
    3) Effects of site status on community composition
          A) Bray-Curtis dissimilarities (Species-abundance matrix)
          B) Non-metric multidimensional scaling (NMDS) (‘metaMDS’ function in vegan)  
          
# ncf 
Confirmation of sampling independence using non-parametric spatial covariance functions.

```{r}
#remove unidentified bee species
BeeID2<-subset(BeeID, GenusSpecies!="Unknown")

#Create abundance matrix by site 
Beeabmatrix <- BeeID2 %>% group_by(Site, GenusSpecies) %>% summarize(abundance = length(unique(Number)))
Beeabmatrix <- Beeabmatrix %>%
  spread(key = GenusSpecies, value = abundance)
Beeabmatrix<- Beeabmatrix %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
Beeabmatrix<- Beeabmatrix %>% 
  column_to_rownames("Site")

#ncf
SiteInfo<- SiteInfo %>% arrange(SITE)
  
x<- SiteInfo$LONGITUDE
y<- SiteInfo$LATITUDE
z<- Beeabmatrix

ncf<- spline.correlog(x=x, y=y, z=z, latlon=T, resamp=1000)
S1<- plot(ncf)

```

# 1A Bee abundances

**Comparison by month**  
First, calculate the bee abundance across sites and months. 

```{r, warning=FALSE}
#Calculate bee abundance at each site at each month
Beeabmonth<- BeeID %>% group_by(Site, Treatment, Month) %>% summarize(beeab = length(unique(Number)))
#add missing rows to df
  #create missing rows
df1<- data.frame (c("C17", "C26", "C29"), 
                  c("Control","Control","Control"),
                  c("August","August","August"),
                  c(0,0,0))
  #Naming the Data Frame
names(df1) <- c("Site", "Treatment", "Month", "beeab")  
  #Using rbind() function to insert above observation  
Beeabmonth <- rbind(Beeabmonth, df1) 

Beeabpooled <- BeeID %>% group_by(Site, Treatment) %>% summarize(beeab = length(unique(Number)))

```

Create linear model and run ANOVA. Assumptions: assumptions of homoscedasticity (Levene's test) and normality (histograms). Variances are not equal by Levene's test and data is not normally distributed. Residuals v fitted also shows not equal variances. Normal Q-Q is heavily skewed. Shapiro-Wilk test residuals are not normally distributed.

```{r}
#create linear model
lmbeeabmonth <- lm(beeab ~ Treatment * Month, data=Beeabmonth) 
anova(lmbeeabmonth)

#Testing if NF changes model
  #add NF to Beeabmonth
  SiteInfo2 <- SiteInfo[,c(2,5)]
  #rename columns to match Beeabmonth
  SiteInfo2 <- SiteInfo2 %>% rename(c(Site=SITE, NF=NATIONAL_FOREST))
  #merge
  Beeabmonth2<-merge (Beeabmonth, SiteInfo2, by='Site')
  #create linear model
  lmbeeabmonth2<- lmer(beeab ~ Treatment * Month + (1|NF), data=Beeabmonth2)
  anova(lmbeeabmonth2)
  #Does not change anything
  
#run anova
anova(lmbeeabmonth)
emout <- emmeans(lmbeeabmonth, ~ Treatment*Month)
pairs(emout)

#assumptions
par(mfrow=c(2,2))
plot(lmbeeabmonth)

```

Plot data.

```{r}
#order by month
Beeabmonth$Month <- factor(Beeabmonth$Month,levels = c("June", "July", "August"))

#create box plots 
fig5A<- ggplot(Beeabmonth, aes(x=Month, y=beeab, fill=Treatment)) + 
   geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab( "Bee abundance")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=42)

BeeabSum <- Beeabmonth %>%
  group_by(Month,Treatment) %>%
  summarise(n = n(),
            mean = mean(beeab))

```


**Comparison by capture method** 

First, calculate the bee abundance across sites and capture method.

```{r, warning=FALSE}
#Calculate bee abundance at each site at each month
Beeabmethod<- BeeID %>% group_by(Site, Treatment, Method) %>% summarize(beeab = length(unique(Number)))

#add missing rows to df
  #create missing rows
df2<- data.frame (c("C17", "C22", "C23","C24","C26","C30"), 
                  c("Control","Control","Control","Control","Control","Control"),
                  c("Net","Net","Net","Net","Net","Net"),
                  c(0,0,0,0,0,0))
  #Naming the Data Frame
names(df2) <- c("Site", "Treatment", "Method", "beeab")  
  #Using rbind() function to insert above observation  
Beeabmethod <- rbind(Beeabmethod, df2) 

#Create dataframe with site, month, method, abundance, and richness
  #site
site <- data.frame(rep(c("T1","T2","T3", "T4","T5",
            "T6","T7","T8","T9","T10",
            "T11","T12","T13","T14","T15",
            "C16","C17","C18","C19","C20",
            "C21","C22","C23","C24","C25",
            "C26","C27","C28","C29","C30"),times=9))
names(site) <- "Site"
Site<-site[order(site$Site), ]
  #month
Month<-rep(c("June","July","August"),times=90)
  #method
Method<-rep(c("Blue vane","Blue vane", "Blue vane",
              "Pan trap","Pan trap","Pan trap",
              "Net","Net","Net"),times=30)
  #dataframe
df1<-data.frame(Site,Month,Method)

#Boxplots of species abundance for each capture method in each period:

  #Calculate bee abundance at each site at each month by method
  Beemethod_month_ab<- BeeID %>% group_by(Site, Month, Method) %>% summarize(beeab = length(unique(Number)))

#merge with dataframe and fill na with zero
  Beemethod_month_ab2 <- merge(Beemethod_month_ab, df1, by = c("Site","Month","Method"), all=TRUE) 
  #change NA cells to 0
Beemethod_month_ab2<- Beemethod_month_ab2 %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
#order by month
Beemethod_month_ab2$Month <- factor(Beemethod_month_ab2$Month,levels = c("June", "July", "August"))

# plot
plot1<- ggplot(Beemethod_month_ab2, aes(x=Month, y=beeab, fill=Method)) + 
   geom_boxplot(outlier.shape = NA, aes(fill=Method))+ scale_fill_grey(start = .5, end = .9)+
  ylab( "Bee abundance")+
  ylim(0,25)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

#Boxplots of species richness for each capture method in each period:

#Calculate bee richness at each site at each month by method
Beemethod_month_rich<- BeeID %>% group_by(Site, Month, Method) %>% summarize(beerich = length(unique(GenusSpecies)))

#merge with dataframe and fill na with zero
  Beemethod_month_rich2 <- merge(Beemethod_month_rich, df1, by = c("Site","Month","Method"), all=TRUE) 
  #change NA cells to 0
Beemethod_month_rich2<- Beemethod_month_rich2 %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
#order by month
Beemethod_month_rich2$Month <- factor(Beemethod_month_rich2$Month,levels = c("June", "July", "August"))

# plot
plot2<- ggplot(Beemethod_month_rich2, aes(x=Month, y=beerich, fill=Method)) + 
   geom_boxplot(outlier.shape = NA, aes(fill=Method))+ scale_fill_grey(start = .5, end = .9)+
  ylab( "Bee richness")+
  ylim(0,16)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

```

Create linear model and run ANOVA. Check assumptions: assumptions of homoscedasticity (Levene's test) and normality (histograms). Variances are not equal by Levene's test and data is not normally distributed. Residuals v fitted also shows not equal variances. Normal Q-Q is heavily skewed. Shapiro-Wilk test residuals are not normally distributed.

```{r}
#create linear model to run tests on assumptions
lmbeeabmethod <- lm(beeab ~ Method, data=Beeabmethod) 

#run anova
anova(lmbeeabmethod)
emout <- emmeans(lmbeeabmethod, ~ Method)
pairs(emout)

#assumptions
par(mfrow=c(2,2))
plot(lmbeeabmethod)

#linear model for method and seasonality
#ABUNDANCE: create linear model to run tests on assumptions
  lmbeeabmethod_month <- lm(beeab ~ Method*Month, data=Beemethod_month_ab2) 
  #run anova
  anova(lmbeeabmethod_month)
#RICHNESS: create linear model to run tests on assumptions
  lmbeerichmethod_month <- lm(beerich ~ Method*Month, data=Beemethod_month_rich2) 
  #run anova
  anova(lmbeerichmethod_month)

```

Plot data.

```{r}
#create box plots 
S4 <- ggplot(Beeabmethod, aes(x=Method, y=beeab, fill=Treatment)) + 
   geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  ylab( "Bee abundance")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=38, hide.ns=TRUE)

S5 <- ggarrange(plot1, plot2,
          labels = c("A", "B"),
          ncol = 1, nrow = 2, common.legend=TRUE,legend="top")

```
**Body size and capture methods**
Analyzing body size proportions across different capture methods. 

```{r}
#Add body size from GenusTraits to BeeID
methodsize <- left_join(BeeID2,traits, by="Genus")

#A) summarize by method
methodsizeA <- methodsize %>% group_by(Method, Size) %>% summarize(Count = length(unique(Number)))
  #create visual
A<- ggplot(methodsizeA, aes(x = Method, y = Count, fill = Size)) +
  geom_col(position = "fill") +
  scale_y_continuous(labels = scales::percent)+
  scale_fill_grey(start = .5, end = .9) +
  ylab( "Proportion")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

#B) summarize by method and treatment
methodsizeB <- methodsize %>% group_by(Method, Treatment, Size) %>% summarize(Count = length(unique(Number)))
  #create visual
B<- ggplot(methodsizeB, aes(x = Method, y = Count, fill = Size)) +
  geom_col(position = "fill") +
  scale_y_continuous(labels = scales::percent)+
  facet_grid(~ Treatment) +
  scale_fill_grey(start = .5, end = .9) +
  ylab( "Proportion")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

#C) summarize by method and month
methodsizeC <- methodsize %>% group_by(Method, Month, Size) %>% summarize(Count = length(unique(Number)))
#order by month
methodsizeC$Month <- factor(methodsizeC$Month,levels = c("June", "July", "August"))

  #create visual
C<- ggplot(methodsizeC, aes(x = Method, y = Count, fill = Size)) +
  geom_col(position = "fill") +
  scale_y_continuous(labels = scales::percent)+
  facet_grid(~ Month) +
  scale_fill_grey(start = .5, end = .9) +
  ylab( "Proportion")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

#Combine plots to make figure 
S6 <- ggarrange(A, B, C,
          labels = c("A", "B", "C"),
          ncol = 1, nrow = 3, common.legend=TRUE,legend="top")

```

Venn diagram

```{r}
#create summary data
Beerichmethod <- BeeID2 %>% group_by(Method, GenusSpecies) %>% summarize(abundance = length(unique(Number)))

#create diagram (S7)
venn.diagram(x = list(
    Beerichmethod %>% filter(Method=="Blue vane") %>% dplyr::select(GenusSpecies) %>% unlist(), 
    Beerichmethod %>% filter(Method=="Net") %>% dplyr::select(GenusSpecies) %>% unlist(),
    Beerichmethod %>% filter(Method=="Pan trap") %>% dplyr::select(GenusSpecies) %>% unlist()),
  category.names = c("Blue vane" , "Net" , "Pan trap"),
   filename = 'S7_venndiagram.png',
  output=TRUE)

```

NMDS to compare bee species composition between capture methods. 

```{r}
#create matrix (rows=site, columns= bee species frequency counts)
abmatrix<- BeeID2 %>% group_by(Site, Method, GenusSpecies) %>% summarize(abundance = length(unique(Number)))
#make species columns (first column as site)
abmatrix <- abmatrix %>%
  spread(key = GenusSpecies, value = abundance)
#change NA cells to 0
abmatrix<- abmatrix %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
#remove method column
abmatrix<-as.data.frame(abmatrix)
abmatrix <- abmatrix %>% dplyr::select(-Method)
#make first column row names
abmatrix$Site <- row.names(abmatrix$Site)

#create metadata
metamatrix<- BeeID2 %>% group_by(Site, Method, GenusSpecies) %>% summarize(abundance = length(unique(Number)))
#make species columns (first column as site)
metamatrix <- metamatrix %>%
  spread(key = GenusSpecies, value = abundance)
#change NA cells to 0
metamatrix<- metamatrix %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
metamatrix<- metamatrix %>% dplyr::select(c(Site,Method))

#create dissimilarity matrix
dist.matrix = as.matrix(vegdist(abmatrix, "bray"))

adonis2(abmatrix~Method, data=metamatrix, permutations=9999, method="bray")
```

## 1B Bee species richness

Calculate bee species richness from bee identification data by site and month. 
```{r}
#create new data frame with the bee species richness at each site by month 

#Calculate bee species richness
Beerich <- BeeID2 %>% group_by(Treatment,Site,Month) %>% 
  summarize(beerich = length(unique(GenusSpecies))) #counts unique values of species names
#add missing rows to df
  #create missing rows
df3<- data.frame (c("Control","Control","Control"),
                  c("C17", "C26", "C29"), 
                  c("August","August","August"),
                  c(0,0,0))
  #Naming the Data Frame
names(df3) <- c("Treatment", "Site", "Month", "beerich")  
  #Using rbind() function to insert above observation  
Beerich <- rbind(Beerich, df3)  

#Save data created
write.csv(Beerich,'BeeSpeciesRichness.csv')

#Bee richness pooled for GLM
Beerich2 <- BeeID2 %>% group_by(Site, Treatment) %>% 
  summarize(beerich = length(unique(GenusSpecies)))
#Save data created
write.csv(Beerich2,'BeeSpeciesRichnesspooled.csv')

```

Plot the species richness data:  
```{r}
#order by month
Beerich$Month <- factor(Beerich$Month,levels = c("June", "July", "August"))

#plot data using ggplot
fig5B<- ggplot(Beerich, aes(x=Month, y=beerich, fill=Treatment)) + 
   geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  labs(y="Bee richness")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=19, hide.ns=TRUE)

```

Create linear model and run ANOVA. 

```{r}
#create linear model 
lmbeerich <- lm(beerich ~ Treatment * Month, data=Beerich) 

#run anova
anova(lmbeerich)
emout <- emmeans(lmbeerich, ~ Treatment*Month)
pairs(emout)

```

## 1C Species diversity  

Create species abundance matrix.
```{r}
#Calculate bee abundance at each site at each month

Beespecies<- BeeID2 %>% group_by(SiteMonth, GenusSpecies) %>% summarize(abundance = length(unique(Number)))

BeeSAM <- Beespecies %>%
  spread(key = GenusSpecies, value = abundance)

#change NA cells to 0
matrix<- BeeSAM %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))

#Edit data so that there are only site-month as row names
matrix<- column_to_rownames(matrix, "SiteMonth") #make fist column the row names
head(matrix) #check data

#save data created
write.csv(matrix,'BeeSAM.csv')
```

The following is used to calculate the species diversity at each sampling time. 

```{r}
#create species diversity dataframe (use same format as construction of species abundance matrix)
Beediversity<- BeeID2 %>% group_by(SiteMonth, Treatment, GenusSpecies) %>% summarize(abundance = length(unique(Number))) %>% spread(key = GenusSpecies, value = abundance)

#Edit data so that there are only site-month 
Beediversity<- dplyr::select(Beediversity, 1, 2) 

#Calculate and add diversity to the existing ‘Beediversity’ data frame
Beediversity$Shannon=diversity(matrix, index="shannon")
Beediversity$Simpson=diversity(matrix, index="simpson")
head(Beediversity) #check data 

#add site and month columns
Beediversity<-separate(data=Beediversity, col=SiteMonth, into=c("Month","Site",sep="-"))
Beediversity<- dplyr::select(Beediversity, -3) 

#Save bee diversity data as csv
write.csv(Beediversity,'BeeDiversity.csv')

#create pooled diversity by site for GLM
Beediversitypooled<- BeeID2 %>% group_by(Site, Treatment, GenusSpecies) %>% summarize(abundance = length(unique(Number))) %>% spread(key = GenusSpecies, value = abundance) %>% dplyr::select(1, 2) 

#Calculate bee abundance at each site
matrixpooled<- BeeID2 %>% group_by(Site, GenusSpecies) %>% summarize(abundance = length(unique(Number))) %>% spread(key = GenusSpecies, value = abundance) %>%
  mutate_all(funs(ifelse(is.na(.), 0, .))) #change NA cells to 0

#Edit data so that there are only site-month as row names
matrixpooled<- column_to_rownames(matrixpooled, "Site") #make fist column the row names
head(matrixpooled) #check data

#Calculate and add diversity to the existing ‘Beediversity’ data frame
Beediversitypooled$Shannon=diversity(matrixpooled, index="shannon")
Beediversitypooled$Simpson=diversity(matrixpooled, index="simpson")
head(Beediversitypooled) #check data 

#Save bee diversity data as csv
write.csv(Beediversitypooled,'BeeDiversitypooled.csv')

```

Plot the species diversity data:  

```{r}
#plot data using ggplot
Beediversity$Month <- factor(Beediversity$Month,levels = c("June", "July", "August"))

fig5C<- ggplot(Beediversity, aes(x=Month, y=Shannon, fill=Treatment)) + 
   geom_boxplot(outlier.shape = NA, aes(fill=Treatment))+ scale_fill_grey(start = .5, end = .9)+
  labs(y="Bee diversity")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  stat_compare_means(method="anova",label =  "p.signif", label.x = 1.5, label.y=2.6, hide.ns=TRUE)

```

Create linear model and run ANOVA. Assumptions: assumptions of homoscedasticity (Levene's test) and normality (histograms). Variances are equal by Levene's test and data is approximately normally distributed. Residuals v fitted also shows approximately equal variances. Normal Q-Q is heavily skewed. Shapiro-Wilk test residuals are not normally distributed. Assumptions mostly met. 

```{r}
#create linear model 
lmbeediversity <- lm(Shannon ~ Treatment * Month, data=Beediversity) 

#run anova
anova(lmbeediversity)
emout <- emmeans(lmbeediversity, ~ Treatment*Month)
pairs(emout)

#assumptions
par(mfrow=c(2,2))
plot(lmbeediversity)

Beediversity %>% group_by(Treatment) %>%
  summarize(Shannon=mean(Shannon))

```

Save compiled bee data for future analyses. 

```{r}
#create list of data frames to combine
data_list <- list(Beeabpooled, Beerich2)

#merge data
BeeStats<-data_list %>% reduce(inner_join, by = c("Site", "Treatment"))  

#save data
write.csv(BeeStats, "BeeStats.csv")

#create figure of combined figures

fig5 <- ggarrange(fig5A, fig5B, fig5C,
                    labels = c("A","B","C"),
                    ncol = 3, nrow = 1, common.legend=TRUE,legend="right")

```

## 2A Sample curves for bee species diversity 
Format data correctly to create species accumulation curves:

```{r}
## LIST FOR CONTROL 
beecurveC<- BeeID2 %>% group_by(Treatment, SiteMonth, GenusSpecies) %>% summarize(abundance = length(unique(Number)))

#remove thinned
beecurveC = filter(beecurveC, Treatment != "Thinned")

#make species columns (first column as treatment)
beecurveC <- beecurveC %>%
  spread(key = SiteMonth, value = abundance)
#remove thinned
beecurveC = filter(beecurveC, Treatment != "Thinned")

#add missing values
beecurveC$AugustC17 <- NA 
beecurveC$AugustC26 <- NA  
beecurveC$AugustC29 <- NA  

#change NA cells to 0
beecurveC<- beecurveC %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
#change all values greater than 1 to 1
beecurveC[3:47] <- lapply(beecurveC[3:47], function(x) ifelse( x>1, 1, x))

#remove column 1 and 2
beecurveC<- beecurveC[,-1]

#calculate row-sums (this will become the incidence frequencies)
beecurveClist<- dplyr::select(beecurveC, - GenusSpecies) %>% {rowSums(.)}


#add total number sampling units
beecurveClist<-c(45,beecurveClist)
#make list
beecurveClist<-list(beecurveClist)

##LIST FOR THINNED
beecurveT<- BeeID2 %>% group_by(Treatment, SiteMonth, GenusSpecies) %>% summarize(abundance = length(unique(Number)))

#remove control
beecurveT = filter(beecurveT, Treatment != "Control")

#make species columns (first column as treatment)
beecurveT <- beecurveT %>%
  spread(key = SiteMonth, value = abundance)

#change NA cells to 0
beecurveT<- beecurveT %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
#change all values greater than 1 to 1
beecurveT[3:47] <- lapply(beecurveT[3:47], function(x) ifelse( x>1, 1, x))

#remove column 1
beecurveT<- beecurveT[,-1]

#calculate row-sums (this will become the incidence frequencies)
beecurveTlist<- dplyr::select(beecurveT, - GenusSpecies) %>% {rowSums(.)}
#add total number sampling units
beecurveTlist<-c(45,beecurveTlist)
#make list
beecurveTlist<-list(beecurveTlist)

#add names to lists
beecurvelist <- setNames((c(beecurveClist, beecurveTlist)), c("Control", "Thinned"))

```

Analyzing and graphing the curves.

```{r}
#create the curve using iNEXT
#SAMPLE BASED (Not used in publication)
t <- seq(1, 90, by=10)
out <- iNEXT(beecurvelist, q=c(0, 1, 2), datatype="incidence_freq", size=t)

#INDIVIDUAL BASED
  #format data frame (column 1 species names as row names, then treatment)
beecurve <- BeeID2 %>% 
  group_by(GenusSpecies, Treatment) %>% 
  summarize(abundance = length(unique(Number)))

  #move treatment to seperate columns
beecurve <- spread(beecurve,
                        key = Treatment,
                        value = abundance)
  #change NA cells to 0
beecurve <- beecurve %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
  #make first column row names
beecurve <- beecurve %>% column_to_rownames(var="GenusSpecies")
  #Change values to integer
beecurve$Control <- as.integer(beecurve$Control)
beecurve$Thinned <- as.integer(beecurve$Thinned)

 #Individual-based R/E curves
out2<- iNEXT(beecurve, q=c(0,1,2), datatype="abundance")

  #Figure S8
ggiNEXT(out2, type=1, facet.var="order", color.var="site", grey=TRUE)+
    theme_classic(base_size = 12) + 
  theme(legend.position="right")

# Sample‐size‐based R/E curves
S8<- ggiNEXT(out, type=1, facet.var="order", color.var="site", grey=TRUE) + 
  theme_classic(base_size = 12) + 
  theme(legend.position="right")

```
    
## 3A Bray-Curtis dissimilarities (Species-abundance matrix)

Using the species-abundance matrix ("matrix") created earlier, transform into Bray-Curtis dissimilarities. Analyze the effects of site status on community composition using the ‘adonis2’ function (permutational multivariate analysis of variance, n permutations = 9999) in the R add-on package ‘vegan’ V2.5-522.

```{r}
#create matrix (rows=site, columns= bee species frequency counts)
abmatrix<- BeeID2 %>% group_by(Site, GenusSpecies) %>% summarize(abundance = length(unique(Number)))
#make species columns (first column as site)
abmatrix <- abmatrix %>%
  spread(key = GenusSpecies, value = abundance)
#change NA cells to 0
abmatrix<- abmatrix %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
#make first column row names
abmatrix <- abmatrix %>% column_to_rownames(var="Site")

#create metadata
metamatrix<- BeeID2 %>% group_by(Site, Treatment, GenusSpecies) %>% summarize(abundance = length(unique(Number)))
#make species columns (first column as site)
metamatrix <- metamatrix %>%
  spread(key = GenusSpecies, value = abundance)
#change NA cells to 0
metamatrix<- metamatrix %>%
  mutate_all(funs(ifelse(is.na(.), 0, .)))
metamatrix<- metamatrix %>% dplyr::select(c(Site,Treatment))

#create dissimilarity matrix
dist.matrix = as.matrix(vegdist(abmatrix, "bray"))
adonis2(abmatrix~Treatment, data=metamatrix, permutations=9999, method="bray")

```          

## 3B Non-metric multidimensional scaling (NMDS)

Create visual of the results using non-metric multidimensional scaling (NMDS), produced with the ‘metaMDS’ function in package ‘vegan’.  

First we have to create the NMDS model and extract the site and species scores.

```{r}
#create NMDS value
NMDSmodel<- metaMDS(abmatrix, k=2)
treat=c(rep("Control",15),rep("Thinned",15))
ordiplot(NMDSmodel,type="n")
ordihull(NMDSmodel,groups=treat,draw="polygon",col="grey90",label=F)
orditorp(NMDSmodel,display="sites",col=c(rep("purple",15),rep("blue",15)), air=0.01,cex=1.25)

#build a data frame with NMDS coordinates and metadata
MDS1 = NMDSmodel$points[,1]
MDS2 = NMDSmodel$points[,2]
NMDS = data.frame(NMDS1 = MDS1, NMDS2 = MDS2, Treatment = treat)

#Plot data
Thinned <- NMDS[NMDS$Treatment == "Thinned", ][chull(NMDS[NMDS$Treatment == 
    "Thinned", c("NMDS1", "NMDS2")]), ]  # hull values for thinned
Control <- NMDS[NMDS$Treatment == "Control", ][chull(NMDS[NMDS$Treatment == 
    "Control", c("NMDS1", "NMDS2")]), ]  # hull values for control

hull.data <- rbind(Thinned, Control)  #combine thinned and control

#stress to annotate plot
NMDSmodel$stress

S9<- ggplot() + 
   geom_polygon(data=hull.data,aes(x=NMDS1,y=NMDS2,fill=Treatment,group=Treatment),alpha=0.30) + # add the convex hulls
  geom_point(data=NMDS,aes(x=NMDS1,y=NMDS2,shape=Treatment, fill=Treatment),size=4) + # add the point markers
  scale_fill_grey(start = .3, end = .7)+
  coord_equal() +
  theme_classic() 

```

## Bipartite analysis 

The following section is to analyze the plant-pollinator (flower-bee) network. Specifically, the goal is to	analyze number of linkages and interactions. To perform this analysis I will use the "bipartite" package (https://cran.r-project.org/web/packages/bipartite/vignettes/Intro2bipartite.pdf).

```{r}
#data with only netting
BeesNet<- filter(BeeID, Method == "Net")

FloralInteractions<- BeesNet %>% group_by(Treatment, Flower, GenusSpecies) %>% summarize(Count = length(unique(Number)))

#Remove not recorded values
FloralInteractions<-FloralInteractions[!(FloralInteractions$Flower=="Not recorded"),]
FloralInteractions<-FloralInteractions[!(FloralInteractions$GenusSpecies=="Unknown"),]

#Remove Wood and Ground entries 
FloralInteractions<-FloralInteractions[!(FloralInteractions$Flower=="Ground"|FloralInteractions$Flower=="Wood"),]

FloralInteractions<- as.data.frame(FloralInteractions) #convert to df

#total number of interactions (NOT unique; unique interactions calculated below)
FloralInteractions %>% 
  group_by(Treatment) %>% 
  summarise(interactions= sum(Count))

```

Once data is correctly formatted, then you can make the interaction matrix: 

```{r}
#create web (i.e., interaction matrix)
Web<-frame2webs(FloralInteractions, varnames=c("Flower","GenusSpecies","Treatment", "Count"), type.out="list") #create matrix
#calculate c scores
sapply(frame2webs(FloralInteractions,varnames=c("Flower","GenusSpecies","Treatment", "Count"),type.out="list"), networklevel, index=c("connectance", "C score"))

```

Visualize the data:

```{r}
### Color by family (colors assigned based on number of taxa in each family)

##Format data
FloralInteractions2<- BeesNet %>% group_by(Treatment, Flower, GenusSpecies, Family) %>% summarize(Count = length(unique(Number)))

#Remove not recorded values
FloralInteractions2<-FloralInteractions2[!(FloralInteractions2$Flower=="Not recorded"),]
#Remove Wood and Ground entries 
FloralInteractions2<-FloralInteractions2[!(FloralInteractions2$Flower=="Ground"|FloralInteractions2$Flower=="Wood"),]
FloralInteractions2<-FloralInteractions2[!(FloralInteractions2$GenusSpecies=="Unknown"),]

#Add family-genusspecies column
FloralInteractions2$FamilySpecies<-paste(FloralInteractions2$Family,FloralInteractions2$GenusSpecies,sep=" - ")

FloralInteractions2<- as.data.frame(FloralInteractions2) #convert to df

#Create web with each species with species; colored by family
Web2<-frame2webs(FloralInteractions2, varnames=c("FamilySpecies","Flower","Treatment", "Count"), type.out="list") #create matrix

#Visualization
par(font = 3) #italics
data(Web2)
#Control 
plotweb(Web2$Control, col.low=c("#0072B2","#0072B2","#0072B2",
                               "#CC79A7", "#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7",
                               "#F0E442","#F0E442","#F0E442","#F0E442","#F0E442",
                    "#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73", "#009E73","#009E73"),
        text.rot=90, method="normal", y.lim=c(-1.5,3))

#Thinned
par(font = 3) #italics
data(Web2)

plotweb(Web2$Thinned,method="normal", col.low=c("#0072B2","#0072B2","#0072B2","#0072B2","#0072B2","#0072B2","#0072B2","#0072B2",
                               "#CC79A7", "#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7", "#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7","#CC79A7",
                               "#E69F00","#E69F00","#E69F00","#E69F00","#E69F00","#E69F00","#E69F00","#E69F00","#E69F00",
                               "#F0E442","#F0E442","#F0E442","#F0E442","#F0E442","#F0E442","#F0E442","#F0E442",
                    "#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73","#009E73"), 
	text.rot=90, y.lim=c(-1.5,3))

```

#Analyse the data
Network metrics:
-	Network-level specialization (H2′) (networklevel function)
-	Modularity (computemodules function, with method set to “Beckett)
-	Weighted nestedness (WNODF) (networklevel function)

```{r}
#Network-level specialization and WNODF
networklevel(Web$Control, index="H2")
networklevel(Web$Thinned, index="H2")

#Weighted nestedness (WNODF)
networklevel(Web$Control, index="weighted NODF")
networklevel(Web$Thinned, index="weighted NODF")

Cdegree<- specieslevel(Web$Control, index= "degree", level="higher")
sum(Cdegree$degree)

Tdegree<- specieslevel(Web$Thinned, index= "degree", level="higher")
sum(Tdegree$degree)

#Modularity
modC<-computeModules(Web$Control, method="Beckett") 
plotModuleWeb(modC, weighted=TRUE) #S10A
modC@likelihood

modT<-computeModules(Web$Thinned, method="Beckett") 
plotModuleWeb(modT, weighted=TRUE) #S10B
modT@likelihood

```
#Comparing metrics to a null model 

***NETWORK LEVEL SPECIALIZATION*** 

```{r}
#Control
Iobs <- networklevel(Web$Control, index="H2")

nulls <- nullmodel(web=Web$Control, N=1000, method='r2d') # takes a while!
Inulls <- sapply(nulls, networklevel, index="H2")

plot(density(Inulls), xlim=c(0, 1), lwd=2, main="H2'")
abline(v=Iobs, col="red", lwd=2)
  #p-value based on z score (observed-null)/sd
z<- ((Iobs-mean(Inulls))/sd(Inulls))
1-pnorm(z)

#Thinned
Iobs2 <- networklevel(Web$Thinned, index="H2")

nulls2 <- nullmodel(web=Web$Thinned, N=1000, method='r2d') # takes a while!
Inulls2 <- sapply(nulls2, networklevel, index="H2")

plot(density(Inulls2), xlim=c(0, 1), lwd=2, main="H2'")
abline(v=Iobs2, col="red", lwd=2)
  #p-value based on z score (observed-null)/sd
z<- ((Iobs2-mean(Inulls2))/sd(Inulls2))
1-pnorm(z)

## Comparing differences (is difference between H2 significant?)

# Write a function to compute the desired statistic, e.g. the difference
# between thinned and control:
meandiff <- function(webs){
  obs <- sapply(webs, networklevel, index="H2")
  mean(obs[1] - obs[2])}

(observed <- meandiff(Web))

## Creating a null model: 

nulllist <- lapply(Web, nullmodel, N=1, method="r2d")

#Repeat this procedure 1000 times
res <- 1:1000
for (i in 1:1000){ # takes a few minutes !!
nulllist <- sapply(Web, nullmodel, N=1, method="r2d")
res[i] <- meandiff(nulllist)
}

#depict with histograms and compute p-value
hist(res, xlim=c(-0.4, 0.4), border="white", col="grey")
abline(v=observed, col="red", lwd=2)
# compute p-value as proportion smaller or than observed
sum(res < observed)/length(res) *2 # *2 for two-tailed test

#p-value based on z score (observed-null)/sd
z<- ((observed-mean(res))/sd(res))
pnorm(z)

#p-value based on z-score and delta transformed value
deltadif<- (Iobs-mean(Inulls))-(Iobs2-mean(Inulls2))

z<- (((deltadif)-mean(res))/sd(res))
pnorm(z)

hist(res, xlim=c(-0.4, 0.4), border="white", col="grey")
abline(v=deltadif, col="red", lwd=2)

```

***WEIGHTED NESTEDNESS***

```{r}
#Control
Iobs <- networklevel(Web$Control, index="weighted NODF")

nulls <- nullmodel(web=Web$Control, N=1000, method='r2d') # takes a while!
Inulls <- sapply(nulls, networklevel, index="weighted NODF")

plot(density(Inulls), xlim=c(-1, 5), lwd=2, main="WNODF'")
abline(v=Iobs, col="red", lwd=2)
  #p-value based on z score (observed-null)/sd
z<- ((Iobs-mean(Inulls))/sd(Inulls))
pnorm(z)

#Thinned
Iobs2 <- networklevel(Web$Thinned, index="weighted NODF")

nulls2 <- nullmodel(web=Web$Thinned, N=1000, method='r2d') # takes a while!
Inulls2 <- sapply(nulls2, networklevel, index="weighted NODF")

plot(density(Inulls2), xlim=c(5, 20), lwd=2, main="WNODF")
abline(v=Iobs, col="red", lwd=2)
  #p-value based on z score (observed-null)/sd
z<- ((Iobs2-mean(Inulls2))/sd(Inulls2))
pnorm(z)

# Write a function to compute the desired statistic, e.g. the difference
# between thinned and control:
meandiff <- function(webs){
  obs <- sapply(webs, networklevel, index="weighted NODF")
  mean(obs[1] - obs[2])}

(observed <- meandiff(Web))

## Creating a null model: 

nulllist <- lapply(Web, nullmodel, N=1, method="r2d")

meandiff(Web)

#Repeat this procedure 1000 times
res <- 1:1000
for (i in 1:1000){ # takes a few minutes !!
nulllist <- sapply(Web, nullmodel, N=1, method="r2d")
res[i] <- meandiff(nulllist)
}

#depict with histograms and compute p-value
hist(res, xlim=c(-14, -2), border="white", col="grey")
abline(v=observed, col="red", lwd=2)
# compute p-value as proportion smaller or than observed
sum(res < observed)/length(res) *2 # *2 for two-tailed test

#p-value based on z score (observed-null)/sd
z<- ((observed-mean(res))/sd(res))
1-pnorm(z)

#p-value based on z-score and delta transformed value
deltadif<- (Iobs-mean(Inulls))-(Iobs2-mean(Inulls2))

z<- (((deltadif)-mean(res))/sd(res))
1-pnorm(z)
  #depict with histograms
hist(res, xlim=c(-15, 5), border="white", col="grey")
abline(v=deltadif, col="red", lwd=2)

```
***MODULARITY***
Methods based on Dormann & Strauss (2013). 

```{r}
#Create web not separated by treatment
Web_mod<-frame2webs(FloralInteractions, varnames=c("Flower","GenusSpecies", "Count"), type.out="list") #create matrix

#Create null models (THIS WILL TAKE A COUPLE HOURS)
nulls <- nullmodel(Web_mod$'1', N=100, method="r2d")
modules.nulls <- sapply(nulls, computeModules)
like.nulls <- sapply(modules.nulls, function(x) x@likelihood)

#Calculate z scores comparing observed to nulls 
(z <- (modC@likelihood - mean(like.nulls))/sd(like.nulls))
1-pnorm(z)
(z <- (modT@likelihood - mean(like.nulls))/sd(like.nulls))
1-pnorm(z)

#Observed difference
obsdif<- modC@likelihood-modT@likelihood

#create lists of differences in Q (modularity) of null models
res <- 1:1000
for (i in 1:1000){ # takes a few minutes !!
res[i] <- sample(like.nulls,1, replace=FALSE)-sample(like.nulls,1, replace=FALSE)
}

#depict with histograms and compute p-value
hist(res, xlim=c(-.2, .2), border="white", col="grey")
abline(v=obsdif, col="red", lwd=2)
# compute p-value as proportion smaller or than observed
sum(res < obsdif)/length(res) *2 # *2 for two-tailed test

#p-value based on z score (observed-null)/sd
z<- ((obsdif-mean(res))/sd(res))
1-pnorm(z)

#p-value based on z-score and delta transformed value
deltadif<- (modC@likelihood - mean(like.nulls))-(modT@likelihood - mean(like.nulls))

z<- (((deltadif)-mean(res))/sd(res))
1-pnorm(z)

#depict with histograms and compute p-value
hist(res, xlim=c(-.2, .2), border="white", col="grey")
abline(v=deltadif, col="red", lwd=2)
# compute p-value as proportion smaller or than observed
sum(res < deltadif)/length(res) *2 # *2 for two-tailed test

#Using modularity to identifying species with important roles in the network

null.cz <- lapply(modules.nulls, czvalues)
# compute 95
null.cs <- sapply(null.cz, function(x) x$c) # c-values across all species in nulls
quantile(null.cs, 0.95) 
null.zs <- sapply(null.cz, function(x) x$z) # z-values across all species in nulls
quantile(null.zs, na.rm=TRUE, 0.95) 
# this can now serve as thresholds for identifying particularly uncommonly high c-values


###FIGURE S10
#Control
  #lower (S10B)
cz_B <- czvalues(modC, level="lower")
cz_B <- data.frame(sapply(cz_B,c))
# Plot
S10B <- ggplot(cz_B, aes(x = c, y = z))+
  geom_point(size=2)+
  xlim(0,1)+
  ylim(-1.3,3)+
  geom_vline(xintercept = 0.72)+
  geom_hline(yintercept = 1.792843)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        panel.border = element_rect(color = "black", fill = NA, size = 1))

  #higher (S10A)
cz_A <- czvalues(modC, level="higher")
cz_A <- data.frame(sapply(cz_A,c))
# Plot
S10A <- ggplot(cz_A, aes(x = c, y = z))+
  geom_point(size=2)+
  xlim(0,1)+
  ylim(-1.3,3)+
  geom_vline(xintercept = 0.72)+
  geom_hline(yintercept = 1.792843)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        panel.border = element_rect(color = "black", fill = NA, size = 1))


#Thinned
  #lower (S10D)
cz_D <- czvalues(modT, level="lower")
cz_D <- data.frame(sapply(cz_D,c))
cz_D <- cz_D[order(-cz_D$c), ]
usda_names <- (c("ACMI2", "CEAR4", "HEVI4", "ERCA14"))
# Plot
S10D <- ggplot(cz_D, aes(x = c, y = z))+
  geom_point(size=2)+
  xlim(0,1)+
  ylim(-1.3,3)+
  geom_vline(xintercept = 0.72)+
  geom_hline(yintercept = 1.792843)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        panel.border = element_rect(color = "black", fill = NA, size = 1))+
   geom_text_repel(
    data = filter(cz_D, c>.72),
    label = usda_names,
    size=4, size=6, box.padding = unit(0.2, "lines"), 
    point.padding = unit(0.5, "lines"),
    hjust = 0,
    nudge_x = 0.05,
    direction="y"
  )

  #higher (S10C)
cz_C <- czvalues(modT, level="higher")
cz_C <- data.frame(sapply(cz_C,c))
cz_C <- cz_C[order(-cz_C$c), ]
names1 <- (c("BOBI", "BORU", "LADI", "BOCE", "APME", "BOHU", "ANSP_D", "COSP_B", "HECA", "HOAL", "OSBR"))
cz_C <- cz_C[order(-cz_C$z), ]
names2 <- (c("ASCA", "BONE", "OSJU", "LASS"))

# Plot
S10C <- ggplot(cz_C, aes(x = c, y = z))+
  geom_point(size=2)+
  xlim(0,1)+
  ylim(-1.3,3)+
  geom_vline(xintercept = 0.72)+
  geom_hline(yintercept = 1.792843)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        panel.border = element_rect(color = "black", fill = NA, size = 1))+
   geom_text_repel(
    data = filter(cz_C, c>.72),
    label = names1,
    size=4, size=6, box.padding = unit(0.2, "lines"), 
    point.padding = unit(0.5, "lines"),
    hjust = 0,
    nudge_x = 0.05,
    direction="y"
  )+
   geom_text_repel(
    data = filter(cz_C, z>1.792843),
    label = names2,
    size=4, size=6, box.padding = unit(0.2, "lines"), 
    point.padding = unit(0.5, "lines"),
    hjust = 0,
    nudge_x = 0.05,
    direction="y"
  )

#Combine plots
S10 <- ggarrange(S10A, S10B, S10C, S10D,
                    labels = c("A","B","C", "D"),
                    ncol = 2, nrow = 2)

```

# Structural Equation Model

This section is used to construct and analyze a structural equation model (SEM). The SEMs were fit using the r package piecewiseSEM following Lefcheck (2016). Model evaluation based on methods from Shipley (2009).

Format data and normalize values: 

```{r}
#normalize values
#calculate means and sd
means<- SEMvars %>% group_by() %>% 
  summarise_at(vars(Trees_ha:interactionrich), mean)

sd<- SEMvars %>% group_by() %>% 
  summarise(across(Trees_ha:interactionrich ,~sd(.x, na.rm=TRUE)))

#calculate z scores into new dataframe
SEMvars_norm <- transform(SEMvars, 
                          Trees_ha=(Trees_ha-means$Trees_ha)/sd$Trees_ha,
                          BA=(BA-means$BA)/sd$BA,
                          QMD=(QMD-means$QMD)/sd$QMD,
                          Sky=(Sky-means$Sky)/sd$Sky,
                          floralab=(floralab-means$floralab)/sd$floralab,
                   floralrich=(floralrich-means$floralrich)/sd$floralrich,
                          beeab = (beeab-means$beeab)/sd$beeab,
                          beerich = (beerich-means$beerich)/sd$beerich,
                          Shannon = (Shannon-means$Shannon)/sd$Shannon,
                          Simpson = (Simpson-means$Simpson)/sd$Simpson,
                          Bare=(Bare-means$Bare)/sd$Bare, 
                          Forb=(Forb-means$Forb)/sd$Forb,
                          Grass=(Grass-means$Grass)/sd$Grass, 
                          Litter=(Litter-means$Litter)/sd$Litter, 
                          Rock=(Rock-means$Rock)/sd$Rock,
                          Shrub=(Shrub-means$Shrub)/sd$Shrub, 
                          Tree=(Tree-means$Tree)/sd$Tree,
                          Wood=(Wood-means$Wood)/sd$Wood,
                          Volume=(Volume-means$Volume)/sd$Volume,
                          MeanTemp=(MeanTemp-means$MeanTemp)/sd$MeanTemp,
                          MaxTemp=(MaxTemp-means$MaxTemp)/sd$MaxTemp,
                          MinTemp=(MinTemp-means$MinTemp)/sd$MinTemp,
                   interactionab=(interactionab-means$interactionab)/sd$interactionab,
                   interactionrich=(interactionrich-means$interactionrich)/sd$interactionrich)

write.csv(SEMvars_norm, "SEMvarsnorm.csv")

#remove unknown
BeeID2<-subset(BeeID, GenusSpecies!="Unknown")

#data with only netting
BeesNet<- filter(BeeID2, Method == "Net")

#abundance
Netbeeab<- BeesNet %>% group_by(Site) %>% summarize(beeab2 = length(unique(Number)))
#add missing rows to df
  #create missing rows
df2<- data.frame (c("C17", "C22", "C23","C24","C26","C30"),
                  c(0,0,0,0,0,0))
  #Naming the Data Frame
names(df2) <- c("Site", "beeab2")  
  #Using rbind() function to insert above observation  
Netbeeab <- rbind(Netbeeab, df2) 

#normalize values
#calculate means and sd
means2<- Netbeeab %>% group_by() %>% 
  summarise_at(vars(beeab2), mean)

sd2<- Netbeeab %>% group_by() %>% 
  summarise(across(beeab2 ,~sd(.x, na.rm=TRUE)))

#calculate z scores into new dataframe
Netbeeab_norm <- transform(Netbeeab, 
                          beeab2 = (beeab2-means2$beeab2)/sd2$beeab2)

Netbeeab_norm <- as.data.frame(Netbeeab_norm)

##RICHNESS##
Netbeerich<- BeesNet %>% group_by(Site) %>% summarize(beerich2 = length(unique(GenusSpecies)))
  #create missing rows
df3<- data.frame (c("C17", "C22", "C23","C24","C26","C30"),
                  c(0,0,0,0,0,0))
  #Naming the Data Frame
names(df3) <- c("Site", "beerich2")  
  #Using rbind() function to insert above observation  
Netbeerich <- rbind(Netbeerich, df3)

#normalize values
#calculate means and sd
means3<- Netbeerich %>% group_by() %>% 
  summarise_at(vars(beerich2), mean)

sd3<- Netbeerich %>% group_by() %>% 
  summarise(across(beerich2 ,~sd(.x, na.rm=TRUE)))

#calculate z scores into new dataframe
Netbeerich_norm <- transform(Netbeerich, 
                          beerich2 = (beerich2-means3$beerich2)/sd3$beerich2)

Netbeerich_norm <- as.data.frame(Netbeerich_norm)
                          
```

Create SEM, using data from net captures only.

```{r}
# Add net only data to vars df
#merge data
vars <- SEMvars_norm
vars2<- inner_join (vars, Netbeeab_norm, by = "Site") 
vars2<- inner_join (vars2, Netbeerich_norm, by = "Site")

bee_pSEM2 <- psem(
  #LMM models
  lme(beeab2 ~ Bare + MaxTemp + floralab + floralrich, random = ~ 1 | Site, data = vars2),
  lme(beerich2 ~ Bare + MaxTemp + floralab + floralrich, random = ~ 1 | Site, data = vars2),
  lme(floralab ~ Sky + Bare, random = ~ 1 | Site, data = vars2),
  lme(floralrich ~ Sky + Bare, random = ~ 1 | Site, data = vars2),
  lme(interactionab ~ floralrich + floralab + beerich2 + beeab2, random = ~ 1 | Site, data = vars2),
  lme(interactionrich ~ floralrich + floralab + beerich2 + beeab2, random = ~ 1 | Site, data = vars2),
  lme(MaxTemp ~ Sky, random = ~1 | Site, data = vars2),
     #correlated errors
  floralab %~~% floralrich,
  beeab2 %~~% beerich2,
  interactionab %~~% interactionrich)
 
(new.summary2 <- summary(bee_pSEM2, .progressBar = F))

dSep(bee_pSEM2)

coefficents2 <- new.summary2$coefficients

write.csv(coefficents2, "SEMcoef_Net.csv")

```


## Linear regressions (Figure 4)

Linear regressions to compare floral resources to forest structure (BA).

```{r}
#Floral abundance vs  BA
fig4A<- ggscatter(SEMvars,x="BA",y="floralab",shape="Treatment",
              add="reg.line",
              conf.int =TRUE)+
    stat_cor(aes(label = paste(..rr.label.., sep = "~`,`~")),method="spearman",label.x=35, label.y=300, r.accuracy = 0.001)+
  stat_regline_equation(label.x=35, label.y=250)+
  ylab("Floral abundance")+
  xlab("Basal area")+
  ylim(-75,300)+
  theme(legend.title = element_blank())

#floral species richness vs  BA
fig4B <- ggscatter(SEMvars,x="BA",y="floralrich",shape="Treatment",
              add="reg.line",
              conf.int =TRUE)+
   stat_cor(aes(label = paste(..rr.label.., sep = "~`,`~")),method="spearman",label.x=35, label.y=20, r.accuracy = 0.001)+
  stat_regline_equation(label.x=35, label.y=17)+
  ylab("Floral richness")+
  xlab("Basal area")+
  theme(legend.title = element_blank())

```
Linear regressions to compare floral resources (floral species richness) to bee assemblages measures.

```{r}
#floral species richness vs bee abundance 
fig4C <- ggscatter(SEMvars,x="floralrich",y="beeab",shape="Treatment",
              add="reg.line",
              conf.int =TRUE)+
    stat_cor(aes(label = paste(..rr.label.., sep = "~`,`~")),method="spearman",label.x=12,label.y=125, r.accuracy = 0.001)+
  stat_regline_equation(label.x=12,label.y=110)+
  ylab("Bee abundance")+
  xlab("Floral richness")+
  theme(legend.title = element_blank())

#floral species richness vs  Bee richness
fig4D<- ggscatter(SEMvars,x="floralrich",y="beerich",shape="Treatment",
              add="reg.line",
              conf.int =TRUE)+
    stat_cor(aes(label = paste(..rr.label.., sep = "~`,`~")),method="spearman",label.x=12,label.y=50, r.accuracy = 0.001)+
  stat_regline_equation(label.x=12,label.y=45)+
  ylab("Bee richness")+
  xlab("Floral richness")+
  theme(legend.title = element_blank())

#floral species richness vs  Bee diversity
fig4E<- ggscatter(SEMvars,x="floralrich",y="Shannon",shape="Treatment",
              add="reg.line",
              conf.int =TRUE)+
   stat_cor(aes(label = paste(..rr.label.., sep = "~`,`~")),method="spearman",label.x=12,label.y=5, r.accuracy = 0.001)+
  stat_regline_equation(label.x=12,label.y=4.5)+
  ylab("Bee diversity (H')")+
  xlab("Floral richness")+
  theme(legend.title = element_blank())

#final figure
fig4<- ggarrange(fig4A, fig4B, fig4C, fig4D, fig4E, 
                    labels = c("A","B","C", "D", "E"),
                    ncol = 2, nrow = 3, 
                    common.legend = TRUE, legend ="bottom")

```

## Supplemental material

Additional supplemental material (some included in analyses above). 

Correlation analysis was performed on independent variables and highly correlated variables (≥ 0.60 correlation coefficient) were omitted from analysis. 

```{r}
#rename normalize variables used for SEM
GLMvars_norm <- vars

#dataframe with independent variables
independentvars<- subset(GLMvars_norm, select = c("floralab",
                 "floralrich","Trees_ha","BA","QMD","Sky",
                 "Bare", "Forb", "Grass", "Litter", "Rock", 
                 "Shrub", "Tree", "Wood","Volume","MeanTemp","MaxTemp","MinTemp")) 

coriv <-cor(independentvars)

source("http://www.sthda.com/upload/rquery_cormat.r")
require("corrplot")
#Figure S12
rquery.cormat(independentvars)

write.csv(coriv, "cor.csv")

```
